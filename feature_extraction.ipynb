{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gt9f7boVsX9j",
        "outputId": "47cd3962-8d4e-438d-ab2b-2ee3a1591436"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "from numpy.random import seed\n",
        "seed(123)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "uJRNJPCovjxZ"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-06-19 09:13:39.962134: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "from scripts.audio_feature_extraction_for_file import extract_audio_features_for_frames\n",
        "from scripts.utils import create_and_save_lookup_table\n",
        "from scripts.biosignal_data_extraction import get_biosignal_data_for_frames\n",
        "from scripts.video_landmark_extraction import get_mediapipe_pose_estimation_for_frames, get_dlib_face_estimation_for_frames\n",
        "from scripts.csv_out import write_features_to_csv\n",
        "from scripts.process_data import process_data_folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "HgJbjrSZ3YH4"
      },
      "outputs": [],
      "source": [
        "# Save the lookup table to a CSV file -- only run once to get the file if it doesn't already exist \n",
        "# create_and_save_lookup_table('frequency_to_note.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "roX8ZQ6vFZ-R"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 414ms/step\n"
          ]
        }
      ],
      "source": [
        "# Test that feature extraction works as expected on test audio\n",
        "TEST_FILE = 'media/test_audio.wav'\n",
        "features, cleaned_time = extract_audio_features_for_frames(TEST_FILE, reference_audio=True, frame_duration_ms=30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "86\n"
          ]
        }
      ],
      "source": [
        "# Ensure all feature lists have the same length\n",
        "lengths = [len(feature) for feature in features.values()]\n",
        "if len(set(lengths)) != 1:\n",
        "    for feature in features.values():\n",
        "        print(len(feature))\n",
        "    raise ValueError(\"All feature lists must have the same length\")\n",
        "\n",
        "audio_features_length = lengths[0]\n",
        "print(audio_features_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:root:Processing mediapipe pose estimation for media/test_phone_video.mp4.\n",
            "I0000 00:00:1718815179.075748  134257 gl_context.cc:357] GL version: 2.1 (2.1 ATI-4.14.1), renderer: AMD Radeon Pro 570 OpenGL Engine\n",
            "Processing Frames:   0%|          | 0/67 [00:00<?, ?it/s]W0000 00:00:1718815179.380285  185301 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
            "W0000 00:00:1718815179.402179  185301 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
            "/Users/Suvi/miniforge3/envs/data_extract_env/lib/python3.10/site-packages/google/protobuf/symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
            "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n",
            "Processing Frames: 100%|██████████| 67/67 [00:02<00:00, 30.51it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ignoring empty video frame.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# testing getting mediapipe landmark pose per 10ms frame\n",
        "TEST_VIDEO_FILE_PATH = 'media/test_phone_video.mp4'\n",
        "TEST_OUTPUT_DIR_PATH = 'media/output/'\n",
        "\n",
        "pose_landmarks = get_mediapipe_pose_estimation_for_frames(cleaned_time, TEST_VIDEO_FILE_PATH, TEST_OUTPUT_DIR_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "if len(pose_landmarks) != audio_features_length:\n",
        "    raise ValueError(\"Face landmarks and audio features must have the same length\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:root:Processing dlib face landmarks for media/test_phone_video.mp4.\n",
            "Processing Frames: 100%|██████████| 67/67 [00:13<00:00,  5.04it/s]\n"
          ]
        }
      ],
      "source": [
        "face_landmarks = get_dlib_face_estimation_for_frames(cleaned_time, TEST_VIDEO_FILE_PATH, TEST_OUTPUT_DIR_PATH)\n",
        "\n",
        "if len(face_landmarks) != audio_features_length:\n",
        "    raise ValueError(\"Face landmarks and audio features must have the same length\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "#test biosignal extraction \n",
        "TEST_BIO_FILE_PATH = 'media/test_biosignal_data.json'\n",
        "\n",
        "biosignal_data = get_biosignal_data_for_frames(cleaned_time, TEST_BIO_FILE_PATH, frame_duration_ms=30)\n",
        "\n",
        "for channel in biosignal_data:\n",
        "    if len(biosignal_data[channel]) != audio_features_length:\n",
        "        print(len(biosignal_data[channel]))\n",
        "        raise ValueError(\"Biosignal data and audio features must have the same length\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [],
      "source": [
        "# test:\n",
        "file_info = {\n",
        "    'participant_number' : \"001\",\n",
        "    'age' : 24,\n",
        "    'experience_level' : \"Intermediate\",\n",
        "    'phonation' : \"neutral\",\n",
        "    'recording_condition' : \"normal\",\n",
        "    'phrase' : \"simple triad\",\n",
        "    'clip_number' : 1\n",
        "}\n",
        "\n",
        "# TEST csv output for test file \n",
        "TEST_CSV = \"data/output_test.csv\"\n",
        "\n",
        "write_features_to_csv(TEST_CSV, file_info, features, pose_landmarks, face_landmarks, biosignal_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# test feature extraction from file system\n",
        "\n",
        "DIR_IN = '/Volumes/music suvi/MASTERS THESIS UPF/VOICE_DATA_THESIS'\n",
        "CSV_TEST = 'data/real_out_test.csv'\n",
        "LOG_TEST = 'data/processed_folders.log'\n",
        "\n",
        "process_data_folder(DIR_IN, CSV_TEST, LOG_TEST, num_folders_to_process=, frame_duration_ms=30)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FINAL RUNNING PROCESSING OF ALL DATA\n",
        "\n",
        "DIR_IN = '/Volumes/music suvi/MASTERS THESIS UPF/VOICE_DATA_THESIS'\n",
        "CSV_OUT = \"/Volumes/music suvi/MASTERS THESIS UPF/VOICE_DATA_THESIS/voice_data_thesis.csv\"\n",
        "LOG_FILE = \"/Volumes/music suvi/MASTERS THESIS UPF/VOICE_DATA_THESIS/processed_folders.log\"\n",
        "\n",
        "process_data_folder(DIR_IN, CSV_OUT, LOG_FILE, num_folders_to_process=0, frame_duration_ms=30)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
